# AI Infra 面试问题合集

## 一、GPU & CUDA 基础知识
来源：知乎

1. SM结构与资源管理：描述SM（流多处理器）的基本结构。在编写Kernel时，为何需要注意共享内存大小和寄存器文件数量？它们如何影响SM上活跃的线程块数量？

2. 内存层级优化：共享内存和寄存器分别适合存放哪些类型的数据？它们的用量与SM的线程块调度有何关系？

3. Bank冲突：什么是共享内存的Bank冲突？描述其底层结构（如32个Bank），并列举至少两种解决方法（如内存填充、访问模式修改）。

4. 分支发散：Warp内的分支冲突是什么？当warp内部分线程走if，部分走else时，GPU是如何执行的？是否需要等待？

5. TensorCore：项目中是否使用过TensorCore？了解其原理吗（如混合精度计算、Warp级矩阵乘加操作）？

6. 向量化访存：为什么使用float4等向量类型来存取数据？好处是什么（如提升访存吞吐、合并全局内存访问）？

7. 异步与任务图：为什么使用双缓冲优化？了解CUDA Stream和CUDA Graph吗？它们分别用于解决什么问题？

8. GPU通信库：除了MPI，还了解哪些现代GPU通信库（如NCCL）？它们在高性能计算和AI训练中为何至关重要？

9. 性能分析工具：在使用Nsight Computing进行性能分析时，你经常关注哪些与内存相关的指标（如gpu__dram_throughput.avg.pct_of_peak）？会关注L1/Texure Cache的命中率吗？

10. 指令集优化：对GPU指令集优化有了解吗？是否有过PTX汇编或SASS层级的优化经验？

11. 算子特性分析：GEMM（通用矩阵乘）是计算密集型还是访存密集型算子？为什么？

12. GEMM优化库：了解CUTLASS吗？它如何通过对计算、访存层次结构的抽象来高效实现和优化GEMM？

