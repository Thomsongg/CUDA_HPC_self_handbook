# CUDA_HPC_self_handbook
CUDA C++é«˜æ€§èƒ½è®¡ç®—å­¦ä¹ ç¬”è®°ï¼ŒåŒ…å«çŸ¥è¯†æ–‡æ¡£ã€Cuda c++ç¨‹åºæºç ã€æ€§èƒ½åˆ†æç»“æœ

## ğŸ“ é¡¹ç›®ç›®å½•ç»“æ„

â”œâ”€â”€ docs/ # é¡¹ç›®æ–‡æ¡£ </br>
â”œâ”€â”€ experiments/ # å®éªŒä¸æ€§èƒ½åˆ†æ </br>
â”œâ”€â”€ results/ # æµ‹è¯•ä¸å®éªŒç»“æœ </br>
â””â”€â”€ src/ # æºä»£ç 

## ğŸ“š [**docs - çŸ¥è¯†æ–‡æ¡£**](https://github.com/Thomsongg/CUDA_HPC_self_handbook/tree/main/docs)</br>
å­˜æ”¾æœ‰å…³ CUDA é«˜æ€§èƒ½è®¡ç®— åŠ AI Infra å…¨æ ˆçŸ¥è¯†ï¼Œè½¯ç¡¬ä»¶å…¼å…·ã€‚

- [**CUDA C++å¼€å‘æŒ‡å—**](https://github.com/Thomsongg/CUDA_HPC_self_handbook/tree/main/docs/handbook.md)ï¼šä»‹ç» CUDA C++ é«˜æ€§èƒ½è®¡ç®—å¼€å‘ç›¸å…³çŸ¥è¯†ï¼ŒåŒ…å« CUDA æ¶æ„ã€ç»å…¸æ¡ˆä¾‹å’Œ Thrust å¹¶è¡Œåº“ç­‰éƒ¨åˆ†ï¼Œå¹¶åµŒå…¥å„é‡è¦åŠŸèƒ½ç‚¹ç¤ºä¾‹ä»£ç ï¼Œå­˜å…¥ handbook.mdã€‚
- [**ç¡¬ä»¶åŸºç¡€**](https://github.com/Thomsongg/CUDA_HPC_self_handbook/tree/main/docs/HardwareBasics.md)ï¼šè¯¦ç»†ä»‹ç» GPU å’Œ CUDA ç¡¬ä»¶åŸºç¡€çŸ¥è¯†ï¼Œå­˜å…¥ HardwareBasics.md
- [**CUDAä¸ç°ä»£C++**](https://github.com/Thomsongg/CUDA_HPC_self_handbook/tree/main/docs/Cpp_new_features.md)ï¼šä»‹ç» C++æ–°ç‰¹æ€§ï¼ˆ11/17ï¼‰åœ¨ CUDA é«˜æ€§èƒ½è®¡ç®—çš„åº”ç”¨ï¼Œå¦‚ RAIIã€æ™ºèƒ½æŒ‡é’ˆã€Lambda è¡¨è¾¾å¼ã€if constexpr ç­‰é‡è¦ç‰¹æ€§ã€‚
- **å…¶ä»–æ–‡æ¡£**ï¼šåŒ…å«å­¦ä¹ ç›®æ ‡ã€é¢è¯•å‡†å¤‡ç­‰æ–‡æ¡£ã€‚

## ğŸ”¬ [**experiments - å®éªŒä¸åˆ†æ**](https://github.com/Thomsongg/CUDA_HPC_self_handbook/tree/main/experiments)</br>
ä½¿ç”¨ Nsight Compute (UI) å¯¹ CUDA C++ ç¨‹åºè¿›è¡Œæ€§èƒ½æµ‹è¯•äº§ç”Ÿçš„æ–‡ä»¶ï¼Œç”¨äºåˆ†æç¨‹åºæ€§èƒ½ç“¶é¢ˆï¼Œå¹¶é’ˆå¯¹æ€§ä¼˜åŒ–ã€‚

- **ååé‡ (Throughput)**ï¼šGPU å„å™¨ä»¶ååé‡ã€è®¡ç®—ä¸å†…å­˜ååé‡ã€ä¸åŒç²¾åº¦çš„ Roofline æ¨¡å‹
- **è®¡ç®—å¼ºåº¦ (Compute Workload)**ï¼š
- **å†…å­˜è´Ÿè½½ (Compute Workload)**ï¼š
- **å¯åŠ¨æ•°æ® (Launch Statistics)**ï¼š
- **å ç”¨ç‡ (Occupancy)**ï¼š

## ğŸ“Š [**results - è¿è¡Œç»“æœ**](https://github.com/Thomsongg/CUDA_HPC_self_handbook/tree/main/results)</br>
ä¿å­˜ CUDA åŸç¨‹åºåŠä¼˜åŒ–åçš„æµ‹è¯•ç»“æœã€‚


## ğŸ’» [**src - æºä»£ç **](https://github.com/Thomsongg/CUDA_HPC_self_handbook/tree/main/src)</br>
é¡¹ç›®çš„ä¸»è¦æºä»£ç ç›®å½•ï¼ŒåŒ…å«å¤§å‹ä¸”é‡è¦çš„é¡¹ç›®ä»£ç ã€‚

- **çŸ©é˜µä¹˜æ³• (GEMM)**
- **è§„çº¦ (Reduction)**
- **è½¬ç½® (Transpose)**
- **CUDA Stream åº”ç”¨**
- **CUDA C++ æ–°ç‰¹æ€§**



## :memo: å­¦ä¹ ç›®æ ‡
### 1 GPU ç¡¬ä»¶æ¶æ„ & CUDA åŸºç¡€çŸ¥è¯†
#### 1.1 GPUæ¶æ„çŸ¥è¯†ï¼š

1. äº†è§£SMï¼ˆStreaming Multiprocessorï¼‰çš„åŸºæœ¬ç»“æ„ï¼šåŒ…æ‹¬CUDA Coreã€Tensor Coreï¼ˆå¦‚æœæ¶‰åŠï¼‰ã€å†…å­˜å±‚æ¬¡ï¼ˆå¯„å­˜å™¨ã€å…±äº«å†…å­˜ã€L1/L2ç¼“å­˜ã€å¸¸é‡å†…å­˜ã€çº¹ç†å†…å­˜ç­‰ï¼‰ã€‚

2. äº†è§£çº¿ç¨‹è°ƒåº¦çš„åŸºæœ¬å•ä½ï¼šWarpï¼ˆ32ä¸ªçº¿ç¨‹ï¼‰çš„æ¦‚å¿µï¼Œä»¥åŠWarpè°ƒåº¦å™¨å¦‚ä½•å·¥ä½œã€‚

3. äº†è§£ä¸åŒGPUæ¶æ„çš„ç‰¹æ€§ï¼ˆå¦‚Fermiã€Keplerã€Maxwellã€Pascalã€Voltaã€Turingã€Ampereç­‰ï¼‰ï¼Œç‰¹åˆ«æ˜¯ä½ ç›®æ ‡å…¬å¸å¯èƒ½ä½¿ç”¨çš„æ¶æ„ã€‚

#### 1.2 GPUå†…å­˜å±‚æ¬¡ä¸ç¼“å­˜ï¼š

1. ç†è§£å…¨å±€å†…å­˜ã€å…±äº«å†…å­˜ã€å¸¸é‡å†…å­˜ã€çº¹ç†å†…å­˜ã€æœ¬åœ°å†…å­˜ç­‰çš„ç‰¹æ€§å’Œä½¿ç”¨åœºæ™¯ã€‚

2. ç†è§£ç¼“å­˜å±‚æ¬¡ç»“æ„ï¼ˆL1ã€L2ï¼‰ï¼Œä»¥åŠå¦‚ä½•åˆ©ç”¨ç¼“å­˜æé«˜æ€§èƒ½ã€‚

3. ç†è§£åˆå¹¶å†…å­˜è®¿é—®ï¼ˆCoalesced Memory Accessï¼‰çš„æ¦‚å¿µï¼Œä»¥åŠå¦‚ä½•é€šè¿‡è°ƒæ•´å†…å­˜è®¿é—®æ¨¡å¼æ¥å‡å°‘ç¼“å­˜missã€‚

#### 1.3 å†…å­˜è®¿é—®ä¼˜åŒ–ï¼š

1. äº†è§£Bank Conflictï¼ˆå…±äº«å†…å­˜çš„bankå†²çªï¼‰åŠå…¶é¿å…æ–¹æ³•ã€‚

2. äº†è§£å¦‚ä½•é€šè¿‡æ•°æ®å¸ƒå±€ä¼˜åŒ–ï¼ˆä¾‹å¦‚Structure of Arrays vs Array of Structuresï¼‰æ¥æé«˜å†…å­˜è®¿é—®æ•ˆç‡ã€‚

3. äº†è§£é¢„å–ï¼ˆPrefetchingï¼‰æŠ€æœ¯ï¼Œä»¥åŠå¦‚ä½•åˆ©ç”¨å®ƒæ¥éšè—å†…å­˜å»¶è¿Ÿã€‚

#### 1.4 å¹¶è¡Œæ€§ä¸èµ„æºé™åˆ¶ï¼š

1. äº†è§£Occupancyï¼ˆå ç”¨ç‡ï¼‰çš„æ¦‚å¿µï¼Œä»¥åŠå¦‚ä½•é€šè¿‡è°ƒæ•´çº¿ç¨‹å—å¤§å°å’Œèµ„æºä½¿ç”¨æ¥æé«˜Occupancyã€‚

2. äº†è§£å¯„å­˜å™¨å‹åŠ›å¯¹æ€§èƒ½çš„å½±å“ï¼Œä»¥åŠå¦‚ä½•å‡å°‘å¯„å­˜å™¨ä½¿ç”¨ï¼ˆä¾‹å¦‚ä½¿ç”¨å¯åŠ¨è¾¹ç•Œï¼ˆlaunch boundsï¼‰æˆ–è°ƒæ•´ç¼–è¯‘å™¨ä¼˜åŒ–æ ‡å¿—ï¼‰ã€‚

#### 1.4 æŒ‡ä»¤çº§ä¼˜åŒ–ï¼š

1. äº†è§£æŒ‡ä»¤ååé‡ï¼ˆä¾‹å¦‚ï¼Œå•ç²¾åº¦æµ®ç‚¹ã€åŒç²¾åº¦æµ®ç‚¹ã€æ•´æ•°è¿ç®—çš„ååé‡ï¼‰ã€‚

2. äº†è§£æ§åˆ¶æµåˆ†æ­§ï¼ˆBranch Divergenceï¼‰å¯¹æ€§èƒ½çš„å½±å“ï¼Œä»¥åŠå¦‚ä½•é¿å…ã€‚

3. äº†è§£ä½¿ç”¨å†…å»ºå‡½æ•°ï¼ˆintrinsicsï¼‰å’Œæ±‡ç¼–ä»£ç è¿›è¡Œæä¼˜åŒ–ï¼ˆè¿™éƒ¨åˆ†å¯èƒ½ä¸æ˜¯å¿…é¡»ï¼Œä½†äº†è§£æœ‰åŠ©äºç†è§£æ€§èƒ½ç“¶é¢ˆï¼‰ã€‚

#### 1.5 æ€§èƒ½åˆ†æå·¥å…·ï¼š

1. ç†Ÿç»ƒä½¿ç”¨Nsight Systemsï¼ˆå®è§‚æ€§èƒ½åˆ†æï¼‰å’ŒNsight Computeï¼ˆå¾®è§‚å†…æ ¸åˆ†æï¼‰ç­‰å·¥å…·ã€‚

2. èƒ½å¤Ÿé€šè¿‡å·¥å…·è¯†åˆ«æ€§èƒ½ç“¶é¢ˆï¼Œä¾‹å¦‚å†…å­˜å¸¦å®½ç“¶é¢ˆã€è®¡ç®—ç“¶é¢ˆã€æŒ‡ä»¤ååç“¶é¢ˆç­‰ã€‚

#### 1.6 ç¼“å­˜missçš„æ’æŸ¥ä¸ä¼˜åŒ–ï¼š

1. ä½¿ç”¨Nsight Computeå¯ä»¥æ£€æµ‹åˆ°ç¼“å­˜missï¼ˆä¾‹å¦‚L1/L2ç¼“å­˜æœªå‘½ä¸­ç‡ï¼‰ã€‚

2. äº†è§£å¦‚ä½•é€šè¿‡è°ƒæ•´å†…å­˜è®¿é—®æ¨¡å¼ã€æ•°æ®å—å¤§å°ã€æ•°æ®å¸ƒå±€ç­‰æ¥å‡å°‘ç¼“å­˜missã€‚

3. ç†è§£æ—¶é—´å±€éƒ¨æ€§å’Œç©ºé—´å±€éƒ¨æ€§ï¼Œå¹¶æ®æ­¤ä¼˜åŒ–ä»£ç ã€‚

#### 1.7 æ•°æ®ç»“æ„ä¸ç®—æ³•é€‰æ‹©ï¼š

æ ¹æ®è®¿é—®æ¨¡å¼é€‰æ‹©æ•°æ®ç»“æ„ã€‚ä¾‹å¦‚ï¼Œè¿ç»­è®¿é—®çš„æ•°ç»„ï¼ˆO(1)éšæœºè®¿é—®ï¼‰å¯èƒ½æ¯”é“¾è¡¨ï¼ˆO(n)è®¿é—®ï¼‰åœ¨GPUä¸Šæ›´é«˜æ•ˆï¼Œå› ä¸ºæ•°ç»„æ›´å®¹æ˜“å®ç°åˆå¹¶è®¿é—®å’Œç¼“å­˜å‹å¥½ã€‚

ç°å®æ¡ˆä¾‹ï¼šä¾‹å¦‚ï¼Œåœ¨GPUä¸Šå®ç°å“ˆå¸Œè¡¨æ—¶ï¼Œå¯èƒ½ä¼šå› ä¸ºå†²çªå’Œéšæœºè®¿é—®å¯¼è‡´ç¼“å­˜missè¾ƒé«˜ï¼Œè¿™æ—¶å¯ä»¥è€ƒè™‘ä½¿ç”¨å¼€æ”¾å¯»å€æ³•è€Œä¸æ˜¯é“¾åœ°å€æ³•ï¼Œå› ä¸ºå¼€æ”¾å¯»å€æ³•æ›´è¿ç»­ã€‚

#### 1.8 è·¨æ¶æ„å…¼å®¹æ€§ï¼š

äº†è§£ä¸åŒGPUæ¶æ„çš„å·®å¼‚ï¼Œå¹¶ç¼–å†™èƒ½å¤Ÿé€‚åº”å¤šç§æ¶æ„çš„ä»£ç ï¼ˆä¾‹å¦‚ä½¿ç”¨CUDAçš„PTXå’Œç¼–è¯‘é€‰é¡¹ï¼‰ã€‚

#### 1.9 å…¶ä»–ç¡¬ä»¶ç‰¹æ€§ï¼š

äº†è§£GPUçš„PCIeæ€»çº¿ä¼ è¾“ã€NVLinkï¼ˆå¤šGPUé€šä¿¡ï¼‰ã€ç»Ÿä¸€å†…å­˜ï¼ˆUnified Memoryï¼‰ç­‰ã€‚

### 2 CUDAè½¯ä»¶ç¼–ç¨‹
#### 2.1 CUDAæ ¸å¿ƒæ¦‚å¿µ
1. CUDAæ ¸å¿ƒæ¶æ„ï¼šçº¿ç¨‹-çº¿ç¨‹æŸWarp-çº¿ç¨‹å—-ç½‘æ ¼ã€SIMTå•æŒ‡ä»¤å¤šçº¿ç¨‹ã€CUDAæµä¸å¹¶å‘æ‰§è¡Œæ¨¡å¼

#### 2.2 ç»å…¸æ¡ˆä¾‹
1. ã€å…¥é—¨ã€‘å‘é‡åŠ æ³•ï¼šäº†è§£CUDA C++åŸºæœ¬ç¼–ç¨‹è¦ç´ ï¼ŒåŒ…å«kernelæ ¸å‡½æ•°ã€__global__å…³é”®å­—ã€kernelç½‘æ ¼å¤§å°ä¸çº¿ç¨‹å—å¤§å°å®šä¹‰ã€GPUå†…å­˜ç”³è¯·(CudaMalloc)ã€CPU-GPUå†…å­˜è½¬ç§»(CudaMemcpy)ã€GPUå†…å­˜é‡Šæ”¾(CudaFree)ç­‰åŸºæœ¬ç”¨æ³•ã€‚
2. ã€å…¥é—¨ã€‘æ¿€æ´»å‡½æ•°ï¼šReLUã€Sigmoidã€Tanh
3. ã€è¿›é˜¶ã€‘çŸ©é˜µè½¬ç½®Transposeï¼šæœ´ç´ è½¬ç½®(å®¹æ˜“å¼•èµ·bank conflict)ã€ä½¿ç”¨å…±äº«å†…å­˜çš„çŸ©é˜µè½¬ç½®ï¼Œbank conflictçš„æ¦‚å¿µã€åŸç†ã€å¦‚ä½•æ£€æµ‹(ncuæŒ‡ä»¤)ã€è§„é¿æ–¹å¼(paddingã€è°ƒæ•´å…±äº«å†…å­˜è®¿é—®æ¨¡å¼ã€float4å‡å°‘è®¿é—®äº‹åŠ¡)
4. ã€è¿›é˜¶ã€‘å½’çº¦è¿ç®—Reductionï¼šæœ´ç´ å½’çº¦ã€æŠ˜åŠå½’çº¦ã€Warp Shuffleå½’çº¦æ³•(2ç§)ã€ä½¿ç”¨float4ä¼˜åŒ–ã€‚**é‡è¦ï¼Œå¿…é¡»æŒæ¡ï¼ï¼ï¼**
5. ã€è¿›é˜¶ã€‘çŸ©é˜µä¹˜æ³•GEMMï¼šæœ´ç´ çŸ©é˜µä¹˜ã€åˆ©ç”¨kåˆ†å‰²æ€æƒ³çš„å…±äº«å†…å­˜çŸ©é˜µä¹˜(block_tile)ã€ä½¿ç”¨å¯„å­˜å™¨çš„çŸ©é˜µä¹˜(thread_tile)ã€‚**é‡è¦ï¼Œå¿…é¡»æŒæ¡ï¼ï¼ï¼**
6. ã€è¿›é˜¶ã€‘Softmaxç®—å­ï¼šä½¿ç”¨å½’çº¦è¿ç®—çš„ç®—å­å®ç°
7. ã€é«˜çº§ã€‘å…¶ä»–å¤§æ¨¡å‹ç®—å­ï¼šå·ç§¯(Convolution)ã€æ± åŒ–(Pooling)ã€å½’ä¸€(Normalization)
8. ã€å¿…ä¿®ã€‘æ€§èƒ½è¯„ä¼°ï¼šä½¿ç”¨Nsight Computeè¯„ä¼°ç¨‹åºæ€§èƒ½ï¼Œé’ˆå¯¹æ€§ä¼˜åŒ–ï¼›å¯¹äºç»å…¸é—®é¢˜ï¼Œå¦‚bank confilictã€warp divergenceã€partional waveç­‰ï¼Œå¦‚ä½•é‰´åˆ«ã€å¦‚ä½•è§„é¿ä¸ä¼˜åŒ–ã€‚
9. ã€é€‰ä¿®ã€‘ä¼˜ç§€å¼€æºé¡¹ç›®ï¼šä½¿ç”¨CUDA C++ä¼˜åŒ–å…¶ä»–ç®—å­

#### 2.3 ä½¿ç”¨ CUDA Stream å®ç°å¤§æ‰¹é‡æ•°æ®å¤„ç†
1. ä½¿ç”¨ç®€å•çš„**å¤šæµå¹¶å‘**ï¼Œå®ç°å†…å­˜æ•°æ®ä¼ è¾“  `cudaMemcpyAsync` ä¸ GPU æ ¸å‡½æ•°è°ƒç”¨çš„å¼‚æ­¥å®ç°ã€‚
2. å°†**å¤šæµå¹¶å‘**ä¸**äº‹ä»¶åŒæ­¥**æœºåˆ¶ç»“åˆï¼Œå¤„ç†å¤šä¸ªæ ¸å‡½æ•°çš„æµé—´ä¾èµ–é—®é¢˜ -> å‡è®¾ Kernel2 çš„è¾“å…¥ä¾èµ–äº Kernel1 çš„è¾“å‡º
3. æŒæ¡â€œæµæ°´çº¿å¼â€å¤„ç†é€»è¾‘ï¼Œå°†å¤§æ‰¹é‡çš„æ•°æ®æ•°æ®åˆ†å— (Chunks) ï¼Œä½¿ç”¨å¤šä¸ªæµåˆ†æ‰¹æ¬¡å¤„ç†ï¼Œå®ç° CPU-GPU å’Œ GPU çš„è®¡ç®—ä»»åŠ¡ä¸æ•°æ®ä¼ è¾“â€œé‡å  (Overlap)â€ã€‚
